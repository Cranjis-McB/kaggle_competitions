{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vikramsandu/dl-nlp-commonlit-summaries?scriptVersionId=138002461\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"5eb2c6c1","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.011825,"end_time":"2023-07-26T19:09:36.79631","exception":false,"start_time":"2023-07-26T19:09:36.784485","status":"completed"},"tags":[]},"source":["## Goal\n","\n","* The immediate goal is to setup this notebook for training, Inference and submission for LB evaluation. <font color=\"green\">&#10004;</font>\n"]},{"cell_type":"markdown","id":"9bf85746","metadata":{"papermill":{"duration":0.011173,"end_time":"2023-07-26T19:09:36.819556","exception":false,"start_time":"2023-07-26T19:09:36.808383","status":"completed"},"tags":[]},"source":["Let's Create a Controller variable for Training/Submission Mode.\n","\n","* Set **True** for Submission Mode.\n","* Set **False** for Training Mode."]},{"cell_type":"code","execution_count":1,"id":"ae2aba5d","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:36.843913Z","iopub.status.busy":"2023-07-26T19:09:36.843486Z","iopub.status.idle":"2023-07-26T19:09:36.857255Z","shell.execute_reply":"2023-07-26T19:09:36.856371Z"},"papermill":{"duration":0.029118,"end_time":"2023-07-26T19:09:36.859913","exception":false,"start_time":"2023-07-26T19:09:36.830795","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["This notebook is on submission Mode...\n","Make sure to turn off the Internet...\n"]}],"source":["# True if you want to submit the Notebook\n","isSubmit = True\n","\n","if isSubmit:\n","    print(f'This notebook is on submission Mode...')\n","    print(f'Make sure to turn off the Internet...')\n","else:\n","    print(f'This notebook is on Training Mode...')"]},{"cell_type":"markdown","id":"b0e8e615","metadata":{"papermill":{"duration":0.011635,"end_time":"2023-07-26T19:09:36.882727","exception":false,"start_time":"2023-07-26T19:09:36.871092","status":"completed"},"tags":[]},"source":["### Read and Understand Data."]},{"cell_type":"markdown","id":"699fe2de","metadata":{"papermill":{"duration":0.011182,"end_time":"2023-07-26T19:09:36.905042","exception":false,"start_time":"2023-07-26T19:09:36.89386","status":"completed"},"tags":[]},"source":["Here we have two type of files: \n","1. **<span style=\"color:red\">Prompts:</span>** It contains the Question, a title about the text, and the text that needs to be summarized.\n","2. **<span style=\"color:red\">Summaries:</span>** This includes the text summarized by the students, along with the corresponding prompt id and target scores for both content and wording."]},{"cell_type":"code","execution_count":2,"id":"f6f85c8e","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:36.932325Z","iopub.status.busy":"2023-07-26T19:09:36.930462Z","iopub.status.idle":"2023-07-26T19:09:36.93689Z","shell.execute_reply":"2023-07-26T19:09:36.935954Z"},"papermill":{"duration":0.021862,"end_time":"2023-07-26T19:09:36.939079","exception":false,"start_time":"2023-07-26T19:09:36.917217","status":"completed"},"tags":[]},"outputs":[],"source":["# Read Dataset\n","import pandas as pd\n","\n","if not isSubmit:\n","    # Train\n","    prompt_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n","    summary_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n","\n","    print(f'\\nLength of Train Prompt df: {len(prompt_df)}')\n","    print(f'Length of Train Summary df: {len(summary_df)}\\n')\n","\n","    # Display\n","    display(summary_df.sample(5))"]},{"cell_type":"code","execution_count":3,"id":"732ee87e","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:36.964647Z","iopub.status.busy":"2023-07-26T19:09:36.962994Z","iopub.status.idle":"2023-07-26T19:09:36.968117Z","shell.execute_reply":"2023-07-26T19:09:36.96727Z"},"papermill":{"duration":0.019669,"end_time":"2023-07-26T19:09:36.97008","exception":false,"start_time":"2023-07-26T19:09:36.950411","status":"completed"},"tags":[]},"outputs":[],"source":["if not isSubmit:\n","    # Distribution of the Prompt Questions.\n","    print(summary_df['prompt_id'].value_counts())"]},{"cell_type":"code","execution_count":4,"id":"efdfde03","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:36.994591Z","iopub.status.busy":"2023-07-26T19:09:36.994274Z","iopub.status.idle":"2023-07-26T19:09:36.999061Z","shell.execute_reply":"2023-07-26T19:09:36.997981Z"},"papermill":{"duration":0.019377,"end_time":"2023-07-26T19:09:37.001081","exception":false,"start_time":"2023-07-26T19:09:36.981704","status":"completed"},"tags":[]},"outputs":[],"source":["if not isSubmit:\n","    # Number of Unique Students\n","    print(len(summary_df['student_id'].unique()))"]},{"cell_type":"markdown","id":"ae28dd67","metadata":{"papermill":{"duration":0.011426,"end_time":"2023-07-26T19:09:37.023586","exception":false,"start_time":"2023-07-26T19:09:37.01216","status":"completed"},"tags":[]},"source":["**So the Training data contains only 4 Prompt Questions that is being asked to 7165 students.**"]},{"cell_type":"markdown","id":"acbc5c0e","metadata":{"papermill":{"duration":0.0114,"end_time":"2023-07-26T19:09:37.046651","exception":false,"start_time":"2023-07-26T19:09:37.035251","status":"completed"},"tags":[]},"source":["Now Let's understand the Labels."]},{"cell_type":"code","execution_count":5,"id":"c2f68170","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:37.071133Z","iopub.status.busy":"2023-07-26T19:09:37.070798Z","iopub.status.idle":"2023-07-26T19:09:37.075957Z","shell.execute_reply":"2023-07-26T19:09:37.074931Z"},"papermill":{"duration":0.020222,"end_time":"2023-07-26T19:09:37.078062","exception":false,"start_time":"2023-07-26T19:09:37.05784","status":"completed"},"tags":[]},"outputs":[],"source":["if not isSubmit: \n","    # Describe\n","    describe_content_df = summary_df['content'].describe()\n","    describe_wording_df = summary_df['wording'].describe()\n","\n","    print(pd.concat([describe_content_df, describe_wording_df], axis=1))"]},{"cell_type":"markdown","id":"38a2e1d4","metadata":{"papermill":{"duration":0.011138,"end_time":"2023-07-26T19:09:37.100645","exception":false,"start_time":"2023-07-26T19:09:37.089507","status":"completed"},"tags":[]},"source":["* The value of **Content** ranging from -1.72 to 3.90.\n","* Value of the **Wording** is ranging from -1.96 to 4.31.\n","\n","It surely has two classes (Content and Wording) and each class has a continuous output. This problem can be put into the category of **Two-Class Regression.**"]},{"cell_type":"markdown","id":"63767d96","metadata":{"papermill":{"duration":0.012406,"end_time":"2023-07-26T19:09:37.124375","exception":false,"start_time":"2023-07-26T19:09:37.111969","status":"completed"},"tags":[]},"source":["Let's have an overall idea about the number of words (or tokens) in summary text."]},{"cell_type":"code","execution_count":6,"id":"56388246","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:37.153276Z","iopub.status.busy":"2023-07-26T19:09:37.152576Z","iopub.status.idle":"2023-07-26T19:09:37.159556Z","shell.execute_reply":"2023-07-26T19:09:37.158436Z"},"papermill":{"duration":0.024959,"end_time":"2023-07-26T19:09:37.161873","exception":false,"start_time":"2023-07-26T19:09:37.136914","status":"completed"},"tags":[]},"outputs":[],"source":["if not isSubmit:\n","    text_length = summary_df['text'].apply(lambda x: len(x.split(' ')))\n","    print(text_length.describe())\n","    print('\\n')\n","\n","    # Lets Visualize the same.\n","    from matplotlib import pyplot as plt\n","\n","    # Create a histogram using Matplotlib\n","    plt.figure(figsize = (3, 3))\n","    plt.hist(text_length, bins=10, edgecolor='k')\n","    plt.xlabel('Text Length')\n","    plt.ylabel('Frequency')\n","    plt.title(f'Distribution of the Text Length')"]},{"cell_type":"markdown","id":"9f5ec01c","metadata":{"papermill":{"duration":0.012968,"end_time":"2023-07-26T19:09:37.187834","exception":false,"start_time":"2023-07-26T19:09:37.174866","status":"completed"},"tags":[]},"source":["The average text summary length is approximately 76 tokens, with a standard deviation of 54 tokens. Most of the text summaries have a length of less than 200 tokens. That is still in the limit of **BERT** and related models, which accept a **maximum of 512 tokens**. In Future, we might use some of the contextual information from the Prompt text to utilize this token gap properly."]},{"cell_type":"markdown","id":"37041a5d","metadata":{"papermill":{"duration":0.011015,"end_time":"2023-07-26T19:09:37.2116","exception":false,"start_time":"2023-07-26T19:09:37.200585","status":"completed"},"tags":[]},"source":["Let's have an overall idea about the number of words (or tokens) in Prompt Text."]},{"cell_type":"code","execution_count":7,"id":"545c8f2c","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:37.23551Z","iopub.status.busy":"2023-07-26T19:09:37.235187Z","iopub.status.idle":"2023-07-26T19:09:37.240053Z","shell.execute_reply":"2023-07-26T19:09:37.239098Z"},"papermill":{"duration":0.019239,"end_time":"2023-07-26T19:09:37.242122","exception":false,"start_time":"2023-07-26T19:09:37.222883","status":"completed"},"tags":[]},"outputs":[],"source":["if not isSubmit:\n","    text_length = prompt_df['prompt_text'].apply(lambda x: len(x.split(' ')))\n","    # Lets Visualize the same.\n","    print(text_length)"]},{"cell_type":"markdown","id":"d579bcc9","metadata":{"papermill":{"duration":0.01104,"end_time":"2023-07-26T19:09:37.264182","exception":false,"start_time":"2023-07-26T19:09:37.253142","status":"completed"},"tags":[]},"source":["Prompt Text is ranging from 550 to 966 words."]},{"cell_type":"markdown","id":"f4cdf2fe","metadata":{"papermill":{"duration":0.011121,"end_time":"2023-07-26T19:09:37.286599","exception":false,"start_time":"2023-07-26T19:09:37.275478","status":"completed"},"tags":[]},"source":["**We must provide this contextual information (prompt text) along with the text summary to yield better results.**\n","\n","But this will result in a longer document (way longer than transformer can process --512 tokens--), to tackle this we will use longformer.\n","\n","* Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. \n","\n","we'll get back to this later if needed."]},{"cell_type":"markdown","id":"4a13b1b1","metadata":{"papermill":{"duration":0.011179,"end_time":"2023-07-26T19:09:37.308733","exception":false,"start_time":"2023-07-26T19:09:37.297554","status":"completed"},"tags":[]},"source":["### Data Augmentations\n","\n","* **randomly_remove_sentences:** Randomly removes few sentences from the text during Training."]},{"cell_type":"code","execution_count":8,"id":"695fe6ce","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:37.332904Z","iopub.status.busy":"2023-07-26T19:09:37.33257Z","iopub.status.idle":"2023-07-26T19:09:39.011829Z","shell.execute_reply":"2023-07-26T19:09:39.010865Z"},"papermill":{"duration":1.69444,"end_time":"2023-07-26T19:09:39.014381","exception":false,"start_time":"2023-07-26T19:09:37.319941","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"data":{"text/plain":["\"\\n# Example usage:\\nidx = 1003\\ninput_text = summary_df['text'][idx]\\nprint(len(input_text.split(' ')))\\nlabels = torch.tensor(summary_df.iloc[idx][-2:].tolist())\\nprint(labels)\\nresult_text,labels = randomly_remove_sentences(input_text, labels)\\nprint(len(result_text.split(' ')))\\n\""]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","import random\n","import numpy as np\n","#nltk.download('punkt')  # Download the necessary tokenizer data\n","\n","def randomly_remove_sentences(text, labels, max_prop=3):\n","    # Tokenize the text into sentences\n","    sentences = nltk.sent_tokenize(text)\n","    \n","    # Calculate the number of sentences to be removed\n","    num_sentences_to_remove = random.randint(0, len(sentences)//max_prop)\n","    \n","    # Score to reduce.\n","    #scale = (len(sentences) - num_sentences_to_remove)/len(sentences)\n","    #labels[0] *= scale\n","\n","    # Randomly select sentences to remove\n","    sentences_to_remove = random.sample(sentences, num_sentences_to_remove)\n","\n","    # Create the final text with removed sentences\n","    final_text = \" \".join(sentence for sentence in sentences if sentence not in sentences_to_remove)\n","\n","    return final_text, labels\n","\n","'''\n","# Example usage:\n","idx = 1003\n","input_text = summary_df['text'][idx]\n","print(len(input_text.split(' ')))\n","labels = torch.tensor(summary_df.iloc[idx][-2:].tolist())\n","print(labels)\n","result_text,labels = randomly_remove_sentences(input_text, labels)\n","print(len(result_text.split(' ')))\n","'''"]},{"cell_type":"markdown","id":"27a20641","metadata":{"papermill":{"duration":0.012738,"end_time":"2023-07-26T19:09:39.040057","exception":false,"start_time":"2023-07-26T19:09:39.027319","status":"completed"},"tags":[]},"source":["### Dataset and Dataloaders"]},{"cell_type":"markdown","id":"a0deb9fc","metadata":{"papermill":{"duration":0.012004,"end_time":"2023-07-26T19:09:39.064829","exception":false,"start_time":"2023-07-26T19:09:39.052825","status":"completed"},"tags":[]},"source":["Now Let's define the Dataset Class.\n","\n","The Dataset class in Natural Language Processing (NLP) serves as a fundamental data structure that helps manage and handle textual data for training and evaluation purposes."]},{"cell_type":"code","execution_count":9,"id":"554aaad9","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:39.090214Z","iopub.status.busy":"2023-07-26T19:09:39.089879Z","iopub.status.idle":"2023-07-26T19:09:44.965947Z","shell.execute_reply":"2023-07-26T19:09:44.964956Z"},"papermill":{"duration":5.891706,"end_time":"2023-07-26T19:09:44.968603","exception":false,"start_time":"2023-07-26T19:09:39.076897","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from transformers import AutoTokenizer\n","import numpy as np\n","\n","class CommonLitSummaryDataset(Dataset):\n","    def __init__(self, \n","                 summary_df,\n","                 prompt_df, \n","                 model_name, \n","                 max_length = 256,\n","                 isTest = False,\n","                 aug = False\n","                ):\n","        self.summary_df = summary_df\n","        self.prompt_df = prompt_df\n","        self.max_length = max_length\n","        self.tokz = AutoTokenizer.from_pretrained(model_name)\n","        self.isTest = isTest\n","        self.aug = aug\n","       \n","    def __len__(self):\n","        return len(self.summary_df)\n","    \n","    def __getitem__(self, idx):\n","        \n","        # Get the Summary and It's Corresponding Question\n","        txt_summary = self.summary_df['text'].iloc[idx]\n","        \n","        # Label\n","        if not self.isTest:\n","            label = torch.tensor(self.summary_df.iloc[idx][-2:].tolist())\n","            \n","        # Augmentation only in Train Mode    \n","        if self.aug:\n","            txt_summary, label = randomly_remove_sentences(txt_summary, label)\n","        \n","        prompt_id = self.summary_df['prompt_id'].iloc[idx]\n","        prompt_question = self.prompt_df[self.prompt_df['prompt_id'] == prompt_id]['prompt_question'].iloc[0]\n","        #prompt_txt = self.prompt_df[self.prompt_df['prompt_id'] == prompt_id]['prompt_text'].iloc[0]\n","        \n","        # Concat the Question and Summary.\n","        input_text = 'QUESTION: ' + prompt_question + 'SUMMARY: ' + txt_summary \n","        #+ 'CONTEXT: ' +  prompt_txt\n","        \n","        # Convert the text data into Corresponding Numerical Embeddings.\n","        encodings = self.tokz.encode_plus(input_text, \n","                                          add_special_tokens=True, \n","                                          max_length = self.max_length, \n","                                          padding = 'max_length', \n","                                          truncation = True, \n","                                          return_tensors = 'pt'\n","                                         )\n","        input_ids = encodings['input_ids'].squeeze()\n","        attention_mask = encodings['attention_mask'].squeeze()\n","        \n","        # For Test set, No labels will be available\n","        if self.isTest:\n","            return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask\n","        }\n","            \n","        \n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': label\n","        }"]},{"cell_type":"markdown","id":"8d1d0c83","metadata":{"papermill":{"duration":0.011137,"end_time":"2023-07-26T19:09:44.99142","exception":false,"start_time":"2023-07-26T19:09:44.980283","status":"completed"},"tags":[]},"source":["Before Initialising the Class, We have to split the dataset into two categories. 1) Train 2) Valid"]},{"cell_type":"code","execution_count":10,"id":"c9d61ff1","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:45.015667Z","iopub.status.busy":"2023-07-26T19:09:45.015152Z","iopub.status.idle":"2023-07-26T19:09:45.022021Z","shell.execute_reply":"2023-07-26T19:09:45.021002Z"},"papermill":{"duration":0.021849,"end_time":"2023-07-26T19:09:45.024776","exception":false,"start_time":"2023-07-26T19:09:45.002927","status":"completed"},"tags":[]},"outputs":[],"source":["if not isSubmit:\n","    \n","    isStratified = False\n","    \n","    # Split the dataframe into train and validation sets\n","    from sklearn.model_selection import train_test_split\n","    \n","    if not isStratified:\n","        # Normal Split\n","        train_df, valid_df = train_test_split(summary_df, test_size=0.2, random_state=42)\n","    else:\n","        # Stratified Split\n","        test_prompt_id = ['3b9047']\n","        \n","        # Filter the DataFrame to create train and test sets\n","        train_df = summary_df[~summary_df['prompt_id'].isin(test_prompt_id)].reset_index(drop=True)\n","        valid_df = summary_df[summary_df['prompt_id'].isin(test_prompt_id)].reset_index(drop=True)\n","\n","    \n","    print('Train Prompt IDs: ', train_df['prompt_id'].unique())\n","    print('Valid Prompt IDs: ', valid_df['prompt_id'].unique())"]},{"cell_type":"code","execution_count":11,"id":"d10cb5ee","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:45.048995Z","iopub.status.busy":"2023-07-26T19:09:45.048732Z","iopub.status.idle":"2023-07-26T19:09:45.054269Z","shell.execute_reply":"2023-07-26T19:09:45.053296Z"},"papermill":{"duration":0.019856,"end_time":"2023-07-26T19:09:45.056338","exception":false,"start_time":"2023-07-26T19:09:45.036482","status":"completed"},"tags":[]},"outputs":[],"source":["MAX_LENGTH = 512\n","MODEL_NAME = '/kaggle/input/commonlit-summaries-all-tokenizers/bert_base_cased_tokenizer'\n","\n","if not isSubmit:\n","    \n","    # Initialize Dataset Classes\n","    commonlit_summary_train_ds = CommonLitSummaryDataset(train_df,\n","                                                         prompt_df, \n","                                                         model_name = MODEL_NAME, \n","                                                         max_length = MAX_LENGTH,\n","                                                       #  aug = True\n","                                                        )\n","    commonlit_summary_valid_ds = CommonLitSummaryDataset(valid_df, \n","                                                         prompt_df,  \n","                                                         model_name = MODEL_NAME, \n","                                                         max_length = MAX_LENGTH\n","                                                        )\n","    print(f'Train - {len(commonlit_summary_train_ds)}, Test - {len(commonlit_summary_valid_ds)}')"]},{"cell_type":"markdown","id":"4abe0630","metadata":{"papermill":{"duration":0.011066,"end_time":"2023-07-26T19:09:45.07899","exception":false,"start_time":"2023-07-26T19:09:45.067924","status":"completed"},"tags":[]},"source":["Let's Visualize one Sample to see the working of our Dataset."]},{"cell_type":"code","execution_count":12,"id":"0198d43c","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:45.102869Z","iopub.status.busy":"2023-07-26T19:09:45.10261Z","iopub.status.idle":"2023-07-26T19:09:45.107762Z","shell.execute_reply":"2023-07-26T19:09:45.106811Z"},"papermill":{"duration":0.019234,"end_time":"2023-07-26T19:09:45.109719","exception":false,"start_time":"2023-07-26T19:09:45.090485","status":"completed"},"tags":[]},"outputs":[],"source":["if not isSubmit:\n","\n","    # Tokenizer\n","    tokz =  AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","    print(f'------ Input ----------\\n')\n","    sample = commonlit_summary_train_ds[0]\n","    print(tokz.decode(sample['input_ids']))\n","\n","    print(f'\\n------ Labels ----------\\n')\n","    labels = sample['labels']\n","    print(labels)"]},{"cell_type":"markdown","id":"7f1fa69e","metadata":{"papermill":{"duration":0.011124,"end_time":"2023-07-26T19:09:45.132058","exception":false,"start_time":"2023-07-26T19:09:45.120934","status":"completed"},"tags":[]},"source":["**Dataloader:**\n","\n","Dataloader allows us to group multiple samples into batches, enabling parallel processing and more efficient GPU utilization during training."]},{"cell_type":"code","execution_count":13,"id":"56691d38","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:45.157271Z","iopub.status.busy":"2023-07-26T19:09:45.155833Z","iopub.status.idle":"2023-07-26T19:09:45.161401Z","shell.execute_reply":"2023-07-26T19:09:45.160498Z"},"papermill":{"duration":0.020124,"end_time":"2023-07-26T19:09:45.163585","exception":false,"start_time":"2023-07-26T19:09:45.143461","status":"completed"},"tags":[]},"outputs":[],"source":["# Dataloader\n","from torch.utils.data import DataLoader\n","\n","if not isSubmit:\n","    # Create a data loader for the dataset\n","    batch_size = 16\n","    train_dataloader = DataLoader(commonlit_summary_train_ds, batch_size=batch_size, shuffle=True)\n","    eval_dataloader = DataLoader(commonlit_summary_valid_ds, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","id":"2e980516","metadata":{"papermill":{"duration":0.011324,"end_time":"2023-07-26T19:09:45.186249","exception":false,"start_time":"2023-07-26T19:09:45.174925","status":"completed"},"tags":[]},"source":["### Model Training"]},{"cell_type":"code","execution_count":14,"id":"567a15c5","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:45.210961Z","iopub.status.busy":"2023-07-26T19:09:45.20959Z","iopub.status.idle":"2023-07-26T19:09:52.711214Z","shell.execute_reply":"2023-07-26T19:09:52.709474Z"},"papermill":{"duration":7.518558,"end_time":"2023-07-26T19:09:52.716037","exception":false,"start_time":"2023-07-26T19:09:45.197479","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["from transformers import AutoModelForSequenceClassification, AdamW\n","\n","model_nm = 'bert-base-cased'\n","num_labels = 2\n","\n","if not isSubmit:\n","    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=num_labels)\n","\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(\"\\nTotal number of parameters: \", total_params)\n","\n","    total_size = sum(p.numel() * p.element_size() for p in model.parameters())\n","    print(\"Total size (bytes) of the model: \", total_size)\n","    print(\"Total size (MB) of the model: \", total_size / (1024 * 1024))"]},{"cell_type":"markdown","id":"3be770d4","metadata":{"papermill":{"duration":0.022491,"end_time":"2023-07-26T19:09:52.757437","exception":false,"start_time":"2023-07-26T19:09:52.734946","status":"completed"},"tags":[]},"source":["we need to save the best model during Training based on the **MCRMSE** (mean columnwise root mean squared error) which is the Cost Function/ Metric for this Competition.\n","\n","Let's implement this."]},{"cell_type":"code","execution_count":15,"id":"d938b1a4","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:52.782154Z","iopub.status.busy":"2023-07-26T19:09:52.781802Z","iopub.status.idle":"2023-07-26T19:09:52.786946Z","shell.execute_reply":"2023-07-26T19:09:52.786002Z"},"papermill":{"duration":0.01982,"end_time":"2023-07-26T19:09:52.789027","exception":false,"start_time":"2023-07-26T19:09:52.769207","status":"completed"},"tags":[]},"outputs":[],"source":["# Utility: mean columnwise root mean squared error\n","def mcrmse_loss(predictions, targets):\n","    rmse_columnwise = torch.sqrt(torch.mean((predictions - targets)**2, dim=0))\n","    return torch.mean(rmse_columnwise)"]},{"cell_type":"markdown","id":"d151a23b","metadata":{"papermill":{"duration":0.011237,"end_time":"2023-07-26T19:09:52.811973","exception":false,"start_time":"2023-07-26T19:09:52.800736","status":"completed"},"tags":[]},"source":["**Training Loop**"]},{"cell_type":"markdown","id":"975a3baf","metadata":{"papermill":{"duration":0.011135,"end_time":"2023-07-26T19:09:52.834517","exception":false,"start_time":"2023-07-26T19:09:52.823382","status":"completed"},"tags":[]},"source":["In order to have **faster Training**, we will do the followings:\n","\n","1. **Enable mixed precision training** (using half-precision floating-point format or fp16). It utilizes Tensor Cores on supported NVIDIA GPUs to speed up the training process with reduced memory usage.\n","\n","2.  To utilize Kaggle T4/X2 GPU, we will use **DataParallel**. DataParallel allows you to train your model on multiple GPUs simultaneously, distributing the workload across all available GPUs."]},{"cell_type":"code","execution_count":16,"id":"1c46faec","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:52.858684Z","iopub.status.busy":"2023-07-26T19:09:52.858321Z","iopub.status.idle":"2023-07-26T19:09:52.865165Z","shell.execute_reply":"2023-07-26T19:09:52.864265Z"},"papermill":{"duration":0.02132,"end_time":"2023-07-26T19:09:52.86718","exception":false,"start_time":"2023-07-26T19:09:52.84586","status":"completed"},"tags":[]},"outputs":[],"source":["if not isSubmit:\n","    \n","    # Import Dataparallel and mixed precision modules\n","    from torch.cuda.amp import autocast, GradScaler\n","    from torch.nn.parallel import DataParallel\n","\n","    # Check if GPU is available.\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f'DEVICE: {device}\\n')\n","\n","    # Used for Mixed Precision Training\n","    scaler = GradScaler()\n","\n","    # Move your model to the GPU and wrap it with DataParallel (To utilize T4X2)\n","    model = model.to(device)\n","    model = DataParallel(model) "]},{"cell_type":"markdown","id":"06247d69","metadata":{"papermill":{"duration":0.011113,"end_time":"2023-07-26T19:09:52.889863","exception":false,"start_time":"2023-07-26T19:09:52.87875","status":"completed"},"tags":[]},"source":["Let's Train the Model."]},{"cell_type":"code","execution_count":17,"id":"c7e64146","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:52.913989Z","iopub.status.busy":"2023-07-26T19:09:52.913686Z","iopub.status.idle":"2023-07-26T19:09:52.927141Z","shell.execute_reply":"2023-07-26T19:09:52.926254Z"},"papermill":{"duration":0.028015,"end_time":"2023-07-26T19:09:52.929223","exception":false,"start_time":"2023-07-26T19:09:52.901208","status":"completed"},"tags":[]},"outputs":[],"source":["# Visualize progress bar\n","from tqdm import tqdm\n","\n","if not isSubmit:\n","    # Prepare optimizer\n","    optimizer = AdamW(model.parameters(), lr=1e-5)\n","    NUM_EPOCHS = 15\n","\n","    best_eval_loss = float('inf')  # Initialize the best evaluation loss to infinity\n","\n","    for epoch in range(NUM_EPOCHS):\n","        total_loss = 0\n","        model.train() # Set the model to Training mode\n","\n","        for batch in tqdm(train_dataloader):\n","\n","            with autocast():\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                labels = batch['labels'].to(device)\n","\n","                # Forward loop\n","                optimizer.zero_grad() # Ensures Gradient doesn't accumulate.\n","                predictions = model(input_ids=input_ids,\n","                                    attention_mask=attention_mask, \n","                                    labels=labels\n","                                   ).logits\n","\n","                # Compute MCRMSE loss\n","                loss = mcrmse_loss(predictions, labels)\n","\n","            # BackProp\n","            scaler.scale(loss).backward()  # Scale the loss value\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            # Accumulate the Loss\n","            total_loss += loss.item()\n","\n","        # Calculate epoch-level metrics\n","        epoch_loss = total_loss / len(train_dataloader)\n","\n","        # Print epoch-level metrics\n","        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n","        print(f\"Train Loss: {epoch_loss:.4f}\")\n","\n","         # Evaluation\n","        model.eval()  # Set model to evaluation mode\n","        eval_loss = 0\n","\n","        with torch.no_grad():\n","            for batch in eval_dataloader:\n","                with autocast():\n","                    input_ids = batch['input_ids'].to(device)\n","                    attention_mask = batch['attention_mask'].to(device)\n","                    labels = batch['labels'].to(device)\n","\n","                    predictions = model(input_ids=input_ids,\n","                                        attention_mask=attention_mask, \n","                                        labels=labels\n","                                       ).logits\n","                    loss = mcrmse_loss(predictions, labels)\n","\n","                    eval_loss += loss.item()\n","\n","        # Calculate evaluation metrics\n","        eval_epoch_loss = eval_loss / len(eval_dataloader)\n","\n","        # Print evaluation metrics\n","        print(f\"Eval Loss: {eval_epoch_loss:.4f}\")\n","\n","        # Save the Best Model\n","        if eval_epoch_loss < best_eval_loss:\n","            print(f'--------------------------------------')\n","            print(f'Found the best model at Epoch {epoch+1}')\n","            print(f'Validation Loss reduced from {best_eval_loss:.4f} to {eval_epoch_loss:.4f}')\n","            best_eval_loss = eval_epoch_loss\n","            print(f'Saving the best model.')\n","            print(f'--------------------------------------\\n')\n","            \n","            # Access the actual model from the DataParallel object\n","            actual_model = model.module\n","            # Save\n","            actual_model.save_pretrained(\"bert_base_cased_512\")"]},{"cell_type":"markdown","id":"81c7209c","metadata":{"papermill":{"duration":0.011099,"end_time":"2023-07-26T19:09:52.952221","exception":false,"start_time":"2023-07-26T19:09:52.941122","status":"completed"},"tags":[]},"source":["### Model Inference"]},{"cell_type":"markdown","id":"88a3f5cf","metadata":{"papermill":{"duration":0.011052,"end_time":"2023-07-26T19:09:52.974652","exception":false,"start_time":"2023-07-26T19:09:52.9636","status":"completed"},"tags":[]},"source":["Load the Best model."]},{"cell_type":"code","execution_count":18,"id":"d5e53e02","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:09:52.999358Z","iopub.status.busy":"2023-07-26T19:09:52.998445Z","iopub.status.idle":"2023-07-26T19:10:04.251485Z","shell.execute_reply":"2023-07-26T19:10:04.250475Z"},"papermill":{"duration":11.267928,"end_time":"2023-07-26T19:10:04.253897","exception":false,"start_time":"2023-07-26T19:09:52.985969","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["DEVICE: cuda\n","\n"]}],"source":["model_path = '/kaggle/input/commonlit-summaries-all-models/bert_base_cased_512/bert_base_cased_512'\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)\n","\n","# Check if GPU is available.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'DEVICE: {device}\\n')\n","\n","# Model to the Device\n","model = model.to(device)"]},{"cell_type":"markdown","id":"e47236c3","metadata":{"papermill":{"duration":0.011325,"end_time":"2023-07-26T19:10:04.277257","exception":false,"start_time":"2023-07-26T19:10:04.265932","status":"completed"},"tags":[]},"source":["Prepare Test Data Loader."]},{"cell_type":"code","execution_count":19,"id":"9704f387","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:10:04.301841Z","iopub.status.busy":"2023-07-26T19:10:04.301487Z","iopub.status.idle":"2023-07-26T19:10:04.388695Z","shell.execute_reply":"2023-07-26T19:10:04.387712Z"},"papermill":{"duration":0.102288,"end_time":"2023-07-26T19:10:04.391146","exception":false,"start_time":"2023-07-26T19:10:04.288858","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x7a649c7fc6d0>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Read Test DF's.\n","prompt_test_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\n","summary_test_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n","\n","# Initialize Dataset Classes\n","commonlit_summary_test_ds = CommonLitSummaryDataset(summary_test_df,\n","                                                    prompt_test_df, \n","                                                    model_name = MODEL_NAME, \n","                                                    max_length = MAX_LENGTH,\n","                                                    isTest = True\n","                                                    )\n","# Test Dataloader\n","batch_size = 16\n","test_loader = DataLoader(commonlit_summary_test_ds, batch_size=batch_size, shuffle=False)\n","\n","test_loader"]},{"cell_type":"markdown","id":"83f423b0","metadata":{"papermill":{"duration":0.012151,"end_time":"2023-07-26T19:10:04.415857","exception":false,"start_time":"2023-07-26T19:10:04.403706","status":"completed"},"tags":[]},"source":["**Prediction**"]},{"cell_type":"code","execution_count":20,"id":"e781f6df","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:10:04.441289Z","iopub.status.busy":"2023-07-26T19:10:04.440949Z","iopub.status.idle":"2023-07-26T19:10:07.250162Z","shell.execute_reply":"2023-07-26T19:10:07.249127Z"},"papermill":{"duration":2.825475,"end_time":"2023-07-26T19:10:07.2533","exception":false,"start_time":"2023-07-26T19:10:04.427825","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n"]}],"source":["# Eval model\n","model.eval()\n","\n","predictions = []\n","with torch.no_grad():  # Disable gradient computation during inference\n","    for batch in tqdm(test_loader):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        \n","        # Predictions\n","        predictions_batch = model(input_ids=input_ids,\n","                                  attention_mask=attention_mask\n","                                 ).logits\n","        \n","        # Collect predictions from this batch\n","        predictions.extend(predictions_batch.cpu().tolist())\n","        \n","        \n","# Convert to numpy\n","import numpy as np\n","predictions = np.array(predictions)"]},{"cell_type":"markdown","id":"32a97f56","metadata":{"papermill":{"duration":0.012202,"end_time":"2023-07-26T19:10:07.277664","exception":false,"start_time":"2023-07-26T19:10:07.265462","status":"completed"},"tags":[]},"source":["**Submission**"]},{"cell_type":"code","execution_count":21,"id":"40a579c4","metadata":{"execution":{"iopub.execute_input":"2023-07-26T19:10:07.303214Z","iopub.status.busy":"2023-07-26T19:10:07.302891Z","iopub.status.idle":"2023-07-26T19:10:07.320641Z","shell.execute_reply":"2023-07-26T19:10:07.319762Z"},"papermill":{"duration":0.03303,"end_time":"2023-07-26T19:10:07.32272","exception":false,"start_time":"2023-07-26T19:10:07.28969","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>-1.351551</td>\n","      <td>-1.183380</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>-1.349388</td>\n","      <td>-1.176301</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>-1.353758</td>\n","      <td>-1.183159</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>-1.342169</td>\n","      <td>-1.175374</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id   content   wording\n","0  000000ffffff -1.351551 -1.183380\n","1  111111eeeeee -1.349388 -1.176301\n","2  222222cccccc -1.353758 -1.183159\n","3  333333dddddd -1.342169 -1.175374"]},"metadata":{},"output_type":"display_data"}],"source":["# Create a DataFrame\n","data = {\n","    'student_id': summary_test_df['student_id'].tolist(),\n","    'content': predictions[:,0],\n","    'wording': predictions[:,1]\n","}\n","submission_df = pd.DataFrame(data)\n","\n","# Display\n","display(submission_df.head())\n","\n","# Save it for Submission\n","submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","id":"6be2c80b","metadata":{"papermill":{"duration":0.012033,"end_time":"2023-07-26T19:10:07.347737","exception":false,"start_time":"2023-07-26T19:10:07.335704","status":"completed"},"tags":[]},"source":["**TODO:**\n","\n","* FP16 Training <font color=\"green\">&#10004;</font>\n","* Utilize Both of the GPU's <font color=\"green\">&#10004;</font>\n","* Stratified Split <font color=\"green\">&#10004;</font>\n","* Data Augmentations\n","* Model Architecture Tweaking"]},{"cell_type":"markdown","id":"5e2e3d64","metadata":{"papermill":{"duration":0.012449,"end_time":"2023-07-26T19:10:07.372571","exception":false,"start_time":"2023-07-26T19:10:07.360122","status":"completed"},"tags":[]},"source":["**Model Performance Tracker**\n","\n","<style>\n","table {\n","    width: 100%;\n","    border-collapse: collapse;\n","}\n","\n","th, td {\n","    padding: 8px;\n","    text-align: left;\n","}\n","\n","th {\n","    background-color: #FF0000; /* Red color */\n","    color: white;\n","}\n","</style>\n","\n","<table>\n","    <tr>\n","        <th><span style=\"color:red\">S.No.</span></th>\n","        <th><span style=\"color:red\">Seed/ID</span></th>\n","        <th><span style=\"color:red\">Split</span></th>\n","        <th><span style=\"color:red\">Model_name</span></th>\n","        <th><span style=\"color:red\">Input Tokens</span></th>\n","        <th><span style=\"color:red\">DA</span></th>\n","        <th><span style=\"color:red\">Others</span></th>\n","        <th><span style=\"color:red\">CV</span></th>\n","        <th><span style=\"color:red\">LB</span></th>\n","    </tr>\n","    <tr>\n","        <td>1</td>\n","        <td>42</td>\n","        <td>Random</td>\n","        <td>vanilla_bert_base_case</td>\n","        <td>256</td>\n","        <td>None</td>\n","        <td>NA</td>\n","        <td>0.480</td>\n","        <td>0.538</td>\n","    </tr>\n","    <tr>\n","        <td>2</td>\n","        <td>3b9047</td>\n","        <td>Stratify</td>\n","        <td>vanilla_bert_base_cased_stratified_3b9047</td>\n","        <td>256</td>\n","        <td>None</td>\n","        <td>NA</td>\n","        <td>0.670</td>\n","        <td>0.549</td>\n","    </tr>\n","    <tr>\n","        <td>3</td>\n","        <td>42</td>\n","        <td>Random</td>\n","        <td>bert_base_cased_512</td>\n","        <td>512</td>\n","        <td>None</td>\n","        <td>NA</td>\n","        <td>0.465</td>\n","        <td>NA</td>\n","    </tr>\n","</table>\n","\n","\n","**Short Forms:**\n","* **RSD:** Random Sentence Deletion"]},{"cell_type":"code","execution_count":null,"id":"da562f33","metadata":{"papermill":{"duration":0.012032,"end_time":"2023-07-26T19:10:07.396839","exception":false,"start_time":"2023-07-26T19:10:07.384807","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":44.926801,"end_time":"2023-07-26T19:10:11.166887","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-26T19:09:26.240086","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}