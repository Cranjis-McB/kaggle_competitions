{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98822ccb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.011929,
     "end_time": "2023-07-23T08:11:24.553427",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.541498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Goal:\n",
    "\n",
    "* The immediate goal is to setup this notebook for training, Inference and submission for LB evaluation.\n",
    "\n",
    "We'll set more goals once we achieve this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21f9be",
   "metadata": {
    "papermill": {
     "duration": 0.011362,
     "end_time": "2023-07-23T08:11:24.577074",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.565712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's Create a Controller variable for Training/Submission Mode.\n",
    "\n",
    "* Set **True** for Submission Mode.\n",
    "* Set **False** for Training Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21de230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:24.602700Z",
     "iopub.status.busy": "2023-07-23T08:11:24.601832Z",
     "iopub.status.idle": "2023-07-23T08:11:24.618031Z",
     "shell.execute_reply": "2023-07-23T08:11:24.616716Z"
    },
    "papermill": {
     "duration": 0.031664,
     "end_time": "2023-07-23T08:11:24.620346",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.588682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook is on submission Mode...\n",
      "Make sure to turn off the Internet...\n"
     ]
    }
   ],
   "source": [
    "# True if you want to submit the Notebook\n",
    "isSubmit = True\n",
    "\n",
    "if isSubmit:\n",
    "    print(f'This notebook is on submission Mode...')\n",
    "    print(f'Make sure to turn off the Internet...')\n",
    "else:\n",
    "    print(f'This notebook is on Training Mode...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7951aa0",
   "metadata": {
    "papermill": {
     "duration": 0.011653,
     "end_time": "2023-07-23T08:11:24.643348",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.631695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step-1: Read and Understand Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f5a72",
   "metadata": {
    "papermill": {
     "duration": 0.011215,
     "end_time": "2023-07-23T08:11:24.665894",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.654679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we have two type of files: \n",
    "1. **<span style=\"color:red\">Prompts:</span>** It contains the Question, a title about the text, and the text that needs to be summarized.\n",
    "2. **<span style=\"color:red\">Summaries:</span>** This includes the text summarized by the students, along with the corresponding prompt id and target scores for both content and wording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb6d636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:24.691236Z",
     "iopub.status.busy": "2023-07-23T08:11:24.690211Z",
     "iopub.status.idle": "2023-07-23T08:11:24.696655Z",
     "shell.execute_reply": "2023-07-23T08:11:24.695733Z"
    },
    "papermill": {
     "duration": 0.02125,
     "end_time": "2023-07-23T08:11:24.698763",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.677513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "import pandas as pd\n",
    "\n",
    "if not isSubmit:\n",
    "    # Train\n",
    "    prompt_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "    summary_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "\n",
    "    print(f'\\nLength of Train Prompt df: {len(prompt_df)}')\n",
    "    print(f'Length of Train Summary df: {len(summary_df)}\\n')\n",
    "\n",
    "    # Display\n",
    "    display(summary_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85277993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:24.723200Z",
     "iopub.status.busy": "2023-07-23T08:11:24.722322Z",
     "iopub.status.idle": "2023-07-23T08:11:24.727272Z",
     "shell.execute_reply": "2023-07-23T08:11:24.726414Z"
    },
    "papermill": {
     "duration": 0.018994,
     "end_time": "2023-07-23T08:11:24.729364",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.710370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    # Distribution of the Prompt Questions.\n",
    "    print(summary_df['prompt_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0957fcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:24.753388Z",
     "iopub.status.busy": "2023-07-23T08:11:24.752612Z",
     "iopub.status.idle": "2023-07-23T08:11:24.757293Z",
     "shell.execute_reply": "2023-07-23T08:11:24.756386Z"
    },
    "papermill": {
     "duration": 0.019005,
     "end_time": "2023-07-23T08:11:24.759352",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.740347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    # Number of Unique Students\n",
    "    print(len(summary_df['student_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093aad6",
   "metadata": {
    "papermill": {
     "duration": 0.010243,
     "end_time": "2023-07-23T08:11:24.780899",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.770656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**So the Training data contains only 4 Prompt Questions that is being asked to 7165 students.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761f706",
   "metadata": {
    "papermill": {
     "duration": 0.010921,
     "end_time": "2023-07-23T08:11:24.802346",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.791425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now Let's understand the Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaebf811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:24.826883Z",
     "iopub.status.busy": "2023-07-23T08:11:24.825874Z",
     "iopub.status.idle": "2023-07-23T08:11:24.831906Z",
     "shell.execute_reply": "2023-07-23T08:11:24.830945Z"
    },
    "papermill": {
     "duration": 0.020738,
     "end_time": "2023-07-23T08:11:24.834208",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.813470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit: \n",
    "    # Describe\n",
    "    describe_content_df = summary_df['content'].describe()\n",
    "    describe_wording_df = summary_df['wording'].describe()\n",
    "\n",
    "    print(pd.concat([describe_content_df, describe_wording_df], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c31de9",
   "metadata": {
    "papermill": {
     "duration": 0.011189,
     "end_time": "2023-07-23T08:11:24.857099",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.845910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* The value of **Content** ranging from -1.72 to 3.90.\n",
    "* Value of the **Wording** is ranging from -1.96 to 4.31.\n",
    "\n",
    "It surely has two classes (Content and Wording) and each class has a continuous output. This problem can be put into the category of **Two-Class Regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af71e3",
   "metadata": {
    "papermill": {
     "duration": 0.011071,
     "end_time": "2023-07-23T08:11:24.879310",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.868239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's have an overall idea about the number of words (or tokens) in summary text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d3a3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:24.903273Z",
     "iopub.status.busy": "2023-07-23T08:11:24.902942Z",
     "iopub.status.idle": "2023-07-23T08:11:24.909922Z",
     "shell.execute_reply": "2023-07-23T08:11:24.908967Z"
    },
    "papermill": {
     "duration": 0.021473,
     "end_time": "2023-07-23T08:11:24.912251",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.890778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    text_length = summary_df['text'].apply(lambda x: len(x.split(' ')))\n",
    "    print(text_length.describe())\n",
    "    print('\\n')\n",
    "\n",
    "    # Lets Visualize the same.\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    # Create a histogram using Matplotlib\n",
    "    plt.figure(figsize = (3, 3))\n",
    "    plt.hist(text_length, bins=10, edgecolor='k')\n",
    "    plt.xlabel('Text Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of the Text Length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b5da2",
   "metadata": {
    "papermill": {
     "duration": 0.010742,
     "end_time": "2023-07-23T08:11:24.933956",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.923214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The average text summary length is approximately 76 tokens, with a standard deviation of 54 tokens. Most of the text summaries have a length of less than 200 tokens. That is still in the limit of **BERT** and related models, which accept a **maximum of 512 tokens**. In Future, we might use some of the contextual information from the Prompt text to utilize this token gap properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d30d8",
   "metadata": {
    "papermill": {
     "duration": 0.010965,
     "end_time": "2023-07-23T08:11:24.956229",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.945264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step-2: Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b823439e",
   "metadata": {
    "papermill": {
     "duration": 0.011004,
     "end_time": "2023-07-23T08:11:24.978812",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.967808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now Let's define the Dataset Class.\n",
    "\n",
    "The Dataset class in Natural Language Processing (NLP) serves as a fundamental data structure that helps manage and handle textual data for training and evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e9a0e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:25.003178Z",
     "iopub.status.busy": "2023-07-23T08:11:25.002833Z",
     "iopub.status.idle": "2023-07-23T08:11:34.794970Z",
     "shell.execute_reply": "2023-07-23T08:11:34.793878Z"
    },
    "papermill": {
     "duration": 9.808175,
     "end_time": "2023-07-23T08:11:34.798383",
     "exception": false,
     "start_time": "2023-07-23T08:11:24.990208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class CommonLitSummaryDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 summary_df,\n",
    "                 prompt_df, \n",
    "                 model_name, \n",
    "                 max_length = 256,\n",
    "                 isTest = False\n",
    "                ):\n",
    "        self.summary_df = summary_df\n",
    "        self.prompt_df = prompt_df\n",
    "        self.max_length = max_length\n",
    "        self.tokz = AutoTokenizer.from_pretrained('/kaggle/input/commonlit-summaries-all-tokenizers/bert_base_cased_tokenizer')\n",
    "        self.isTest = isTest\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.summary_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Get the Summary and It's Corresponding Question\n",
    "        txt_summary = self.summary_df['text'].iloc[idx]\n",
    "        prompt_id = self.summary_df['prompt_id'].iloc[idx]\n",
    "        txt_question = self.prompt_df[self.prompt_df['prompt_id'] == prompt_id]['prompt_question'].iloc[0]\n",
    "        \n",
    "        # Concat the Question and Summary.\n",
    "        input_text = 'QUESTION: ' + txt_question + 'SUMMARY: ' + txt_summary\n",
    "        \n",
    "        # Convert the text data into Corresponding Numerical Embeddings.\n",
    "        encodings = self.tokz.encode_plus(input_text, \n",
    "                                          add_special_tokens=True, \n",
    "                                          max_length = self.max_length, \n",
    "                                          padding = 'max_length', \n",
    "                                          truncation = True, \n",
    "                                          return_tensors = 'pt'\n",
    "                                         )\n",
    "        input_ids = encodings['input_ids'].squeeze()\n",
    "        attention_mask = encodings['attention_mask'].squeeze()\n",
    "        \n",
    "        # For Test set, No labels will be available\n",
    "        if self.isTest:\n",
    "            return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "            \n",
    "        # Labels\n",
    "        label = torch.tensor(self.summary_df.iloc[idx][-2:].tolist())\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7766007",
   "metadata": {
    "papermill": {
     "duration": 0.014276,
     "end_time": "2023-07-23T08:11:34.829239",
     "exception": false,
     "start_time": "2023-07-23T08:11:34.814963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before Initialising the Class, We have to split the dataset into two categories. 1) Train 2) Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "935bef58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:34.861529Z",
     "iopub.status.busy": "2023-07-23T08:11:34.860108Z",
     "iopub.status.idle": "2023-07-23T08:11:34.868843Z",
     "shell.execute_reply": "2023-07-23T08:11:34.867692Z"
    },
    "papermill": {
     "duration": 0.026743,
     "end_time": "2023-07-23T08:11:34.870984",
     "exception": false,
     "start_time": "2023-07-23T08:11:34.844241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    \n",
    "    isStratified = True\n",
    "    \n",
    "    # Split the dataframe into train and validation sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    if not isStratified:\n",
    "        # Normal Split\n",
    "        train_df, valid_df = train_test_split(summary_df, test_size=0.2, random_state=42)\n",
    "    else:\n",
    "        # Stratified Split\n",
    "        test_prompt_id = ['3b9047']\n",
    "        \n",
    "        # Filter the DataFrame to create train and test sets\n",
    "        train_df = summary_df[~summary_df['prompt_id'].isin(test_prompt_id)].reset_index(drop=True)\n",
    "        valid_df = summary_df[summary_df['prompt_id'].isin(test_prompt_id)].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    print('Train Prompt IDs: ', train_df['prompt_id'].unique())\n",
    "    print('Valid Prompt IDs: ', valid_df['prompt_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1273ad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:34.902842Z",
     "iopub.status.busy": "2023-07-23T08:11:34.902357Z",
     "iopub.status.idle": "2023-07-23T08:11:34.912897Z",
     "shell.execute_reply": "2023-07-23T08:11:34.910559Z"
    },
    "papermill": {
     "duration": 0.036032,
     "end_time": "2023-07-23T08:11:34.917464",
     "exception": false,
     "start_time": "2023-07-23T08:11:34.881432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "\n",
    "    # Initialize Dataset Classes\n",
    "    commonlit_summary_train_ds = CommonLitSummaryDataset(train_df,\n",
    "                                                         prompt_df, \n",
    "                                                         model_name = 'bert-base-cased', \n",
    "                                                         max_length = 256\n",
    "                                                        )\n",
    "    commonlit_summary_valid_ds = CommonLitSummaryDataset(valid_df, \n",
    "                                                         prompt_df,  \n",
    "                                                         model_name = 'bert-base-cased', \n",
    "                                                         max_length = 256\n",
    "                                                        )\n",
    "    print(f'Train - {len(commonlit_summary_train_ds)}, Test - {len(commonlit_summary_valid_ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7bc1ce",
   "metadata": {
    "papermill": {
     "duration": 0.015365,
     "end_time": "2023-07-23T08:11:34.949823",
     "exception": false,
     "start_time": "2023-07-23T08:11:34.934458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's Visualize one Sample to see the working of our Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5526f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:34.981990Z",
     "iopub.status.busy": "2023-07-23T08:11:34.981514Z",
     "iopub.status.idle": "2023-07-23T08:11:34.987826Z",
     "shell.execute_reply": "2023-07-23T08:11:34.986978Z"
    },
    "papermill": {
     "duration": 0.026872,
     "end_time": "2023-07-23T08:11:34.992071",
     "exception": false,
     "start_time": "2023-07-23T08:11:34.965199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "\n",
    "    # Tokenizer\n",
    "    tokz =  AutoTokenizer.from_pretrained('/kaggle/input/commonlit-summaries-all-tokenizers/bert_base_cased_tokenizer')\n",
    "\n",
    "    print(f'------ Input ----------\\n')\n",
    "    sample = commonlit_summary_train_ds[0]\n",
    "    print(tokz.decode(sample['input_ids']))\n",
    "\n",
    "    print(f'\\n------ Labels ----------\\n')\n",
    "    labels = sample['labels']\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ce495",
   "metadata": {
    "papermill": {
     "duration": 0.015694,
     "end_time": "2023-07-23T08:11:35.024005",
     "exception": false,
     "start_time": "2023-07-23T08:11:35.008311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dataloader:**\n",
    "\n",
    "Dataloader allows us to group multiple samples into batches, enabling parallel processing and more efficient GPU utilization during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9742b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:35.056095Z",
     "iopub.status.busy": "2023-07-23T08:11:35.055625Z",
     "iopub.status.idle": "2023-07-23T08:11:35.061505Z",
     "shell.execute_reply": "2023-07-23T08:11:35.060646Z"
    },
    "papermill": {
     "duration": 0.026481,
     "end_time": "2023-07-23T08:11:35.065709",
     "exception": false,
     "start_time": "2023-07-23T08:11:35.039228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if not isSubmit:\n",
    "    # Create a data loader for the dataset\n",
    "    batch_size = 16\n",
    "    train_dataloader = DataLoader(commonlit_summary_train_ds, batch_size=batch_size, shuffle=True)\n",
    "    eval_dataloader = DataLoader(commonlit_summary_valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ab80d1",
   "metadata": {
    "papermill": {
     "duration": 0.015272,
     "end_time": "2023-07-23T08:11:35.097143",
     "exception": false,
     "start_time": "2023-07-23T08:11:35.081871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step-3: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d6d7a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:35.129425Z",
     "iopub.status.busy": "2023-07-23T08:11:35.129057Z",
     "iopub.status.idle": "2023-07-23T08:11:49.401169Z",
     "shell.execute_reply": "2023-07-23T08:11:49.399770Z"
    },
    "papermill": {
     "duration": 14.291119,
     "end_time": "2023-07-23T08:11:49.403887",
     "exception": false,
     "start_time": "2023-07-23T08:11:35.112768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AdamW\n",
    "\n",
    "model_nm = 'bert-base-cased'\n",
    "num_labels = 2\n",
    "\n",
    "if not isSubmit:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=num_labels)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"\\nTotal number of parameters: \", total_params)\n",
    "\n",
    "    total_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    print(\"Total size (bytes) of the model: \", total_size)\n",
    "    print(\"Total size (MB) of the model: \", total_size / (1024 * 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac918d1",
   "metadata": {
    "papermill": {
     "duration": 0.010614,
     "end_time": "2023-07-23T08:11:49.425660",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.415046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we need to save the best model during Training based on the **MCRMSE** (mean columnwise root mean squared error) which is the Cost Function/ Metric for this Competition.\n",
    "\n",
    "Let's implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28d11c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:49.448254Z",
     "iopub.status.busy": "2023-07-23T08:11:49.447868Z",
     "iopub.status.idle": "2023-07-23T08:11:49.452995Z",
     "shell.execute_reply": "2023-07-23T08:11:49.452084Z"
    },
    "papermill": {
     "duration": 0.018821,
     "end_time": "2023-07-23T08:11:49.455137",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.436316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility: mean columnwise root mean squared error\n",
    "def mcrmse_loss(predictions, targets):\n",
    "    rmse_columnwise = torch.sqrt(torch.mean((predictions - targets)**2, dim=0))\n",
    "    return torch.mean(rmse_columnwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e0c50",
   "metadata": {
    "papermill": {
     "duration": 0.011251,
     "end_time": "2023-07-23T08:11:49.477623",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.466372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26fc7d",
   "metadata": {
    "papermill": {
     "duration": 0.011504,
     "end_time": "2023-07-23T08:11:49.500325",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.488821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In order to have **faster Training**, we will do the followings:\n",
    "\n",
    "1. **Enable mixed precision training** (using half-precision floating-point format or fp16). It utilizes Tensor Cores on supported NVIDIA GPUs to speed up the training process with reduced memory usage.\n",
    "\n",
    "2.  To utilize Kaggle T4/X2 GPU, we will use **DataParallel**. DataParallel allows you to train your model on multiple GPUs simultaneously, distributing the workload across all available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e0b4e21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:49.525494Z",
     "iopub.status.busy": "2023-07-23T08:11:49.524516Z",
     "iopub.status.idle": "2023-07-23T08:11:49.531465Z",
     "shell.execute_reply": "2023-07-23T08:11:49.530301Z"
    },
    "papermill": {
     "duration": 0.021961,
     "end_time": "2023-07-23T08:11:49.533652",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.511691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    \n",
    "    # Import Dataparallel and mixed precision modules\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    from torch.nn.parallel import DataParallel\n",
    "\n",
    "    # Check if GPU is available.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'DEVICE: {device}\\n')\n",
    "\n",
    "    # Used for Mixed Precision Training\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Move your model to the GPU and wrap it with DataParallel (To utilize T4X2)\n",
    "    model = model.to(device)\n",
    "    model = DataParallel(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91845de0",
   "metadata": {
    "papermill": {
     "duration": 0.010894,
     "end_time": "2023-07-23T08:11:49.555530",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.544636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's Train the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff68aec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:49.578493Z",
     "iopub.status.busy": "2023-07-23T08:11:49.578172Z",
     "iopub.status.idle": "2023-07-23T08:11:49.591622Z",
     "shell.execute_reply": "2023-07-23T08:11:49.590736Z"
    },
    "papermill": {
     "duration": 0.027579,
     "end_time": "2023-07-23T08:11:49.593767",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.566188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "if not isSubmit:\n",
    "    # Prepare optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    NUM_EPOCHS = 15\n",
    "\n",
    "    best_eval_loss = float('inf')  # Initialize the best evaluation loss to infinity\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        total_loss = 0\n",
    "        model.train() # Set the model to Training mode\n",
    "\n",
    "        for batch in tqdm(train_dataloader):\n",
    "\n",
    "            with autocast():\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                # Forward loop\n",
    "                optimizer.zero_grad() # Ensures Gradient doesn't accumulate.\n",
    "                predictions = model(input_ids=input_ids,\n",
    "                                    attention_mask=attention_mask, \n",
    "                                    labels=labels\n",
    "                                   ).logits\n",
    "\n",
    "                # Compute MCRMSE loss\n",
    "                loss = mcrmse_loss(predictions, labels)\n",
    "\n",
    "            # BackProp\n",
    "            scaler.scale(loss).backward()  # Scale the loss value\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Accumulate the Loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Calculate epoch-level metrics\n",
    "        epoch_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # Print epoch-level metrics\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "         # Evaluation\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        eval_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in eval_dataloader:\n",
    "                with autocast():\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['labels'].to(device)\n",
    "\n",
    "                    predictions = model(input_ids=input_ids,\n",
    "                                        attention_mask=attention_mask, \n",
    "                                        labels=labels\n",
    "                                       ).logits\n",
    "                    loss = mcrmse_loss(predictions, labels)\n",
    "\n",
    "                    eval_loss += loss.item()\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "\n",
    "        # Print evaluation metrics\n",
    "        print(f\"Eval Loss: {eval_epoch_loss:.4f}\")\n",
    "\n",
    "        # Save the Best Model\n",
    "        if eval_epoch_loss < best_eval_loss:\n",
    "            print(f'--------------------------------------')\n",
    "            print(f'Found the best model at Epoch {epoch+1}')\n",
    "            print(f'Validation Loss reduced from {best_eval_loss:.4f} to {eval_epoch_loss:.4f}')\n",
    "            best_eval_loss = eval_epoch_loss\n",
    "            print(f'Saving the best model.')\n",
    "            print(f'--------------------------------------\\n')\n",
    "            \n",
    "            # Access the actual model from the DataParallel object\n",
    "            actual_model = model.module\n",
    "            # Save\n",
    "            actual_model.save_pretrained(\"vanilla_bert_base_cased_stratified_3b9047\")\n",
    "            #torch.save(model.state_dict(), \"vanilla_bert_base_cased.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63335a1",
   "metadata": {
    "papermill": {
     "duration": 0.010432,
     "end_time": "2023-07-23T08:11:49.614801",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.604369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step-4: Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33967337",
   "metadata": {
    "papermill": {
     "duration": 0.010169,
     "end_time": "2023-07-23T08:11:49.635533",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.625364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the Best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24d2247e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:11:49.662738Z",
     "iopub.status.busy": "2023-07-23T08:11:49.661808Z",
     "iopub.status.idle": "2023-07-23T08:12:04.076098Z",
     "shell.execute_reply": "2023-07-23T08:12:04.074990Z"
    },
    "papermill": {
     "duration": 14.432783,
     "end_time": "2023-07-23T08:12:04.078701",
     "exception": false,
     "start_time": "2023-07-23T08:11:49.645918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = '/kaggle/input/commonlit-summaries-all-models/vanilla_bert_base_cased_stratified_3b9047/vanilla_bert_base_cased_stratified_3b9047'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Check if GPU is available.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'DEVICE: {device}\\n')\n",
    "\n",
    "# Model to the Device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79247a",
   "metadata": {
    "papermill": {
     "duration": 0.010905,
     "end_time": "2023-07-23T08:12:04.100713",
     "exception": false,
     "start_time": "2023-07-23T08:12:04.089808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prepare Test Data Loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "683bed9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:12:04.124732Z",
     "iopub.status.busy": "2023-07-23T08:12:04.123270Z",
     "iopub.status.idle": "2023-07-23T08:12:04.242956Z",
     "shell.execute_reply": "2023-07-23T08:12:04.241945Z"
    },
    "papermill": {
     "duration": 0.133767,
     "end_time": "2023-07-23T08:12:04.245209",
     "exception": false,
     "start_time": "2023-07-23T08:12:04.111442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x78892ace46a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Test DF's.\n",
    "prompt_test_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\n",
    "summary_test_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "\n",
    "# Initialize Dataset Classes\n",
    "commonlit_summary_test_ds = CommonLitSummaryDataset(summary_test_df,\n",
    "                                                    prompt_test_df, \n",
    "                                                    model_name = 'bert-base-cased', \n",
    "                                                    max_length = 256,\n",
    "                                                    isTest = True\n",
    "                                                    )\n",
    "# Test Dataloader\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(commonlit_summary_test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff090371",
   "metadata": {
    "papermill": {
     "duration": 0.010634,
     "end_time": "2023-07-23T08:12:04.267243",
     "exception": false,
     "start_time": "2023-07-23T08:12:04.256609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef857ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:12:04.290385Z",
     "iopub.status.busy": "2023-07-23T08:12:04.290060Z",
     "iopub.status.idle": "2023-07-23T08:12:08.569629Z",
     "shell.execute_reply": "2023-07-23T08:12:08.568500Z"
    },
    "papermill": {
     "duration": 4.294027,
     "end_time": "2023-07-23T08:12:08.572212",
     "exception": false,
     "start_time": "2023-07-23T08:12:04.278185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# Eval model\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():  # Disable gradient computation during inference\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        # Predictions\n",
    "        predictions_batch = model(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask\n",
    "                                 ).logits\n",
    "        \n",
    "        # Collect predictions from this batch\n",
    "        predictions.extend(predictions_batch.cpu().tolist())\n",
    "        \n",
    "        \n",
    "# Convert to numpy\n",
    "import numpy as np\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8998e6c",
   "metadata": {
    "papermill": {
     "duration": 0.011505,
     "end_time": "2023-07-23T08:12:08.595913",
     "exception": false,
     "start_time": "2023-07-23T08:12:08.584408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718ae632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T08:12:08.623243Z",
     "iopub.status.busy": "2023-07-23T08:12:08.621721Z",
     "iopub.status.idle": "2023-07-23T08:12:08.643366Z",
     "shell.execute_reply": "2023-07-23T08:12:08.642250Z"
    },
    "papermill": {
     "duration": 0.037687,
     "end_time": "2023-07-23T08:12:08.646112",
     "exception": false,
     "start_time": "2023-07-23T08:12:08.608425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>-1.433658</td>\n",
       "      <td>-1.448832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>-1.430416</td>\n",
       "      <td>-1.444186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>-1.422874</td>\n",
       "      <td>-1.455164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>-1.426212</td>\n",
       "      <td>-1.453039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id   content   wording\n",
       "0  000000ffffff -1.433658 -1.448832\n",
       "1  111111eeeeee -1.430416 -1.444186\n",
       "2  222222cccccc -1.422874 -1.455164\n",
       "3  333333dddddd -1.426212 -1.453039"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "data = {\n",
    "    'student_id': summary_test_df['student_id'].tolist(),\n",
    "    'content': predictions[:,0],\n",
    "    'wording': predictions[:,1]\n",
    "}\n",
    "submission_df = pd.DataFrame(data)\n",
    "\n",
    "# Display\n",
    "display(submission_df.head())\n",
    "\n",
    "# Save it for Submission\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afe6261",
   "metadata": {
    "papermill": {
     "duration": 0.012068,
     "end_time": "2023-07-23T08:12:08.672073",
     "exception": false,
     "start_time": "2023-07-23T08:12:08.660005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TODO:**\n",
    "\n",
    "* FP16 Training <font color=\"green\">&#10004;</font>\n",
    "* Utilize Both of the GPU's <font color=\"green\">&#10004;</font>\n",
    "* Stratified Split <font color=\"green\">&#10004;</font>\n",
    "* Data Augmentations\n",
    "* Model Architecture Tweaking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6aa4bf",
   "metadata": {
    "papermill": {
     "duration": 0.013395,
     "end_time": "2023-07-23T08:12:08.697464",
     "exception": false,
     "start_time": "2023-07-23T08:12:08.684069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Model Performance Tracker**\n",
    "\n",
    "<style>\n",
    "table {\n",
    "    width: 100%;\n",
    "    border-collapse: collapse;\n",
    "}\n",
    "\n",
    "th, td {\n",
    "    padding: 8px;\n",
    "    text-align: left;\n",
    "}\n",
    "\n",
    "th {\n",
    "    background-color: #FF0000; /* Red color */\n",
    "    color: white;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><span style=\"color:red\">S.No.</span></th>\n",
    "        <th><span style=\"color:red\">Seed/ID</span></th>\n",
    "        <th><span style=\"color:red\">Split</span></th>\n",
    "        <th><span style=\"color:red\">Model_name</span></th>\n",
    "        <th><span style=\"color:red\">DA</span></th>\n",
    "        <th><span style=\"color:red\">Others</span></th>\n",
    "        <th><span style=\"color:red\">CV</span></th>\n",
    "        <th><span style=\"color:red\">LB</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>42</td>\n",
    "        <td>Random</td>\n",
    "        <td>vanilla_bert_base_case</td>\n",
    "        <td>None</td>\n",
    "        <td>NA</td>\n",
    "        <td>0.480</td>\n",
    "        <td>0.538</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>3b9047</td>\n",
    "        <td>Stratify</td>\n",
    "        <td>vanilla_bert_base_cased_stratified_3b9047</td>\n",
    "        <td>None</td>\n",
    "        <td>NA</td>\n",
    "        <td>0.670</td>\n",
    "        <td>NA</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f885da",
   "metadata": {
    "papermill": {
     "duration": 0.011847,
     "end_time": "2023-07-23T08:12:08.721137",
     "exception": false,
     "start_time": "2023-07-23T08:12:08.709290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 61.886735,
   "end_time": "2023-07-23T08:12:12.260740",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-23T08:11:10.374005",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
